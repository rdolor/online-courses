{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TFServing_Week1_Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rdolor/online-courses/blob/master/advanced-deployment-scenarios-with-tf/colab/TFServing_Week1_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XXdEnmVvXdUa"
      },
      "source": [
        "# Train Your Own Model and Serve It With TensorFlow Serving\n",
        "\n",
        "In this notebook, you will train a neural network to classify images of handwritten digits from the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. You will then save the trained model, and serve it using [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cSfb9Qd5XdFL"
      },
      "source": [
        "**Warning: This notebook is designed to be run in a Google Colab only**.  It installs packages on the system and requires root access. If you want to run it in a local Jupyter notebook, please proceed with caution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jcLTAmF5Xs2T"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20Deployment/Course%204%20-%20TensorFlow%20Serving/Week%201/Exercises/TFServing_Week1_Exercise.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/lmoroney/dlaicourse/blob/master/TensorFlow%20Deployment/Course%204%20-%20TensorFlow%20Serving/Week%201/Exercises/TFServing_Week1_Exercise.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i2Q8bkjeYTl-"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g8r89tTPI-Kb",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XGFJmWjrKttn",
        "outputId": "79899293-cb37-455d-da72-cf65a8937dfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import json\n",
        "import tempfile\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"\\u2022 Using TensorFlow Version:\", tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "• Using TensorFlow Version: 2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3TOERzhjyXX",
        "colab_type": "code",
        "outputId": "f338b12b-eeae-4648-8214-d8564918a6b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# check the versions (ros)\n",
        "from platform import python_version\n",
        "\n",
        "print('\\u2022 Python version {}'.format(python_version()))\n",
        "print('\\u2022 TF version {}'.format(tf.__version__))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "• Python version 3.6.9\n",
            "• TF version 2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pq-214o8SNt0"
      },
      "source": [
        "## Import the MNIST Dataset\n",
        "\n",
        "The [MNIST](http://yann.lecun.com/exdb/mnist/) dataset contains 70,000 grayscale images of the digits 0 through 9. The images show individual digits at a low resolution (28 by 28 pixels). \n",
        "\n",
        "Even though these are really images, we will load them as NumPy arrays and not as binary image objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7MqDQO0KCaWS",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKnI8v2ukfTG",
        "colab_type": "code",
        "outputId": "56d52a55-9337-40eb-b6c8-92331e7b240f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.shape(train_images)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxTshMsHkXbQ",
        "colab_type": "code",
        "outputId": "d6e5613e-1dad-48a2-8384-494d1e5025aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max(train_images[0].flatten()), max(test_images[0].flatten()), len(train_images), len(test_images)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(255, 255, 60000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AIT-qX0QzLo-",
        "colab": {}
      },
      "source": [
        "# EXERCISE: Scale the values of the arrays below to be between 0.0 and 1.0.\n",
        "train_images = train_images/255.0 \n",
        "test_images = test_images/255.0 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mIDGu-EEzdKb"
      },
      "source": [
        "In the cell below use the `.reshape` method to resize the arrays to the following sizes:\n",
        "\n",
        "```python\n",
        "train_images.shape: (60000, 28, 28, 1)\n",
        "test_images.shape: (10000, 28, 28, 1)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XsIxeG6BzN4t",
        "colab": {}
      },
      "source": [
        "# EXERCISE: Reshape the arrays below.\n",
        "train_images = train_images.reshape(len(train_images),28,28,1)# YOUR CODE HERE\n",
        "test_images = test_images.reshape(len(test_images),28,28,1)# YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aUw8ZxigB1Nx",
        "outputId": "65c28ad4-355a-4ed7-e3ae-e928abecb9c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print('\\ntrain_images.shape: {}, of {}'.format(train_images.shape, train_images.dtype))\n",
        "print('test_images.shape: {}, of {}'.format(test_images.shape, test_images.dtype))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train_images.shape: (60000, 28, 28, 1), of float64\n",
            "test_images.shape: (10000, 28, 28, 1), of float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DcR0OKbOSj0c"
      },
      "source": [
        "## Look at a Sample Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VQMs4v_oSo9v",
        "outputId": "568b0b21-f85f-44e9-ad26-2c3540668536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "idx = 42\n",
        "\n",
        "plt.imshow(test_images[idx].reshape(28,28), cmap=plt.cm.binary)\n",
        "plt.title('True Label: {}'.format(test_labels[idx]), fontdict={'size': 16})\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rn_-9OsPYnDp"
      },
      "source": [
        "## Build a Model\n",
        "\n",
        "In the cell below build a `tf.keras.Sequential` model that can be used to classify the images of the MNIST dataset. Feel free to use the simplest possible CNN. Make sure your model has the correct `input_shape` and the correct number of output units."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EgMgJJynMbVY",
        "outputId": "9b6e35a7-2627-43f8-f04f-0406406a0bc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "# EXERCISE: Create a model.\n",
        "from tensorflow import keras\n",
        "model = keras.Sequential([\n",
        "  keras.layers.Conv2D(input_shape=(28,28,1), filters=8, kernel_size=3, \n",
        "                      strides=2, activation='relu', name='Conv1'),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(10, activation=tf.nn.softmax, name='Softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv1 (Conv2D)               (None, 13, 13, 8)         80        \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1352)              0         \n",
            "_________________________________________________________________\n",
            "Softmax (Dense)              (None, 10)                13530     \n",
            "=================================================================\n",
            "Total params: 13,610\n",
            "Trainable params: 13,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bLzXnZT1YvS6"
      },
      "source": [
        "## Train the Model\n",
        "\n",
        "In the cell below configure your model for training using the `adam` optimizer, `sparse_categorical_crossentropy` as the loss, and `accuracy` for your metrics. Then train the model for the given number of epochs, using the `train_images` array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LTNN0ANGgA36",
        "outputId": "391f399c-5b30-437c-a9ee-945110e03601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# EXERCISE: Configure the model for training.\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "# EXERCISE: Train the model.\n",
        "history = model.fit(train_images, train_labels, epochs=epochs)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3645 - accuracy: 0.9002\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1873 - accuracy: 0.9482\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1460 - accuracy: 0.9592\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1267 - accuracy: 0.9636\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1154 - accuracy: 0.9664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Er_vrDhf4qu5"
      },
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gMD387B93f2g",
        "outputId": "06d9d4dc-b0a4-43c3-d357-68b90f2b6f3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# EXERCISE: Evaluate the model on the test images.\n",
        "results_eval = model.evaluate(test_images, test_labels)# YOUR CODE HERE\n",
        "\n",
        "for metric, value in zip(model.metrics_names, results_eval):\n",
        "    print(metric + ': {:.3}'.format(value))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1136 - accuracy: 0.9666\n",
            "loss: 0.114\n",
            "accuracy: 0.967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WGfmT8M1Yx5y"
      },
      "source": [
        "## Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9uFDoDW_7HX6",
        "outputId": "483e770b-b545-4a8e-de17-1b1408e854db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "MODEL_DIR = tempfile.gettempdir()\n",
        "\n",
        "version = 1\n",
        "\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "\n",
        "if os.path.isdir(export_path):\n",
        "    print('\\nAlready saved a model, cleaning up\\n')\n",
        "    !rm -r {export_path}\n",
        "\n",
        "model.save(export_path, save_format=\"tf\")\n",
        "\n",
        "print('\\nexport_path = {}'.format(export_path))\n",
        "!ls -l {export_path}"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Already saved a model, cleaning up\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: /tmp/1/assets\n",
            "\n",
            "export_path = /tmp/1\n",
            "total 84\n",
            "drwxr-xr-x 2 root root  4096 Apr 30 11:05 assets\n",
            "-rw-r--r-- 1 root root 76081 Apr 30 11:05 saved_model.pb\n",
            "drwxr-xr-x 2 root root  4096 Apr 30 11:05 variables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KziE3e9tY-hH"
      },
      "source": [
        "## Examine Your Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LU4GDF_aYtfQ",
        "outputId": "9ee94e10-8358-4b3b-9e50-9403d10b728f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['Conv1_input'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 28, 28, 1)\n",
            "        name: serving_default_Conv1_input:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['Softmax'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 10)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0430 11:05:08.954962 139658686777216 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "\n",
            "Defined Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'Conv1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'Conv1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'Conv1_input')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'Conv1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'Conv1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AsDTdBGHZAzo"
      },
      "source": [
        "## Add TensorFlow Serving Distribution URI as a Package Source"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EWg9X2QHlbGS",
        "outputId": "0ebe671a-00bf-4381-984e-acecb729c763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "# This is the same as you would do from your command line, but without the [arch=amd64], and no sudo\n",
        "# You would instead do:\n",
        "# echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "# curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n",
        "\n",
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2943  100  2943    0     0  20437      0 --:--:-- --:--:-- --:--:-- 20437\n",
            "OK\n",
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease\n",
            "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:8 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:11 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:13 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Hit:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "108 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4l5XkzqNZNBU"
      },
      "source": [
        "## Install TensorFlow Serving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ygwa9AgRloYy",
        "outputId": "ba89195c-1bc1-4d60-ec66-bccc22eb5838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!apt-get install tensorflow-model-server"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tensorflow-model-server is already the newest version (2.1.0).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 108 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qd_PobAKZWW8"
      },
      "source": [
        "## Run the TensorFlow Model Server\n",
        "\n",
        "You will now launch the TensorFlow model server with a bash script. In the cell below use the following parameters when running the TensorFlow model server:\n",
        "\n",
        "* `rest_api_port`: Use port `8501` for your requests.\n",
        "\n",
        "\n",
        "* `model_name`: Use `digits_model` as your model name. \n",
        "\n",
        "\n",
        "* `model_base_path`: Use the environment variable `MODEL_DIR` defined below as the base path to the saved model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aUgp3vUdU5GS",
        "colab": {}
      },
      "source": [
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kJDhHNJVnaLN",
        "outputId": "c68f9511-a8ee-4f5d-d65c-7ddabb616da9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# EXERCISE: Fill in the missing code below.\n",
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8501 \\\n",
        "  --model_name=exercise_mnist \\\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1 "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting job # 0 in a separate thread.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IxbeiOCUUs2z",
        "outputId": "a2b5c9ae-3910-4ba0-b59d-3462989f5593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "!tail server.log"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-30 11:05:18.017745: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:152] Running initialization op on SavedModel bundle at path: /tmp/1\n",
            "2020-04-30 11:05:18.021286: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:333] SavedModel load for tags { serve }; Status: success: OK. Took 37035 microseconds.\n",
            "2020-04-30 11:05:18.021655: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:105] No warmup data file found at /tmp/1/assets.extra/tf_serving_warmup_requests\n",
            "2020-04-30 11:05:18.021759: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: exercise_mnist version: 1}\n",
            "2020-04-30 11:05:18.022674: I tensorflow_serving/model_servers/server.cc:358] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
            "[warn] getaddrinfo: address family for nodename not supported\n",
            "[evhttp_server.cc : 223] NET_LOG: Couldn't bind to port 8501\n",
            "[evhttp_server.cc : 63] NET_LOG: Server has not been terminated. Force termination now.\n",
            "[evhttp_server.cc : 258] NET_LOG: Server is not running ...\n",
            "2020-04-30 11:05:18.023733: E tensorflow_serving/model_servers/server.cc:380] Failed to start HTTP Server at localhost:8501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6mUrIWVRZdNu"
      },
      "source": [
        "## Create JSON Object with Test Images\n",
        "\n",
        "In the cell below construct a JSON object and use the first three images of the testing set (`test_images`) as your data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2dsD7KQG1m-R",
        "colab": {}
      },
      "source": [
        "# EXERCISE: Create JSON Object\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": test_images[0:3].tolist()})# YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TRdyPl4CZ5CU"
      },
      "source": [
        "## Make Inference Request\n",
        "\n",
        "In the cell below, send a predict request as a POST to the server's REST endpoint, and pass it your test data. You should ask the server to give you the latest version of your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vGvFyuIzW6n6",
        "colab": {}
      },
      "source": [
        "# EXERCISE: Fill in the code below\n",
        "headers = {\"content-type\": \"application/json\"} # YOUR CODE HERE\n",
        "json_response = requests.post('http://localhost:8501/v1/models/exercise_mnist/versions/1:predict', data=data, headers=headers)# YOUR CODE HERE\n",
        "    \n",
        "predictions = json.loads(json_response.text)['predictions']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FtrFMts_ackX"
      },
      "source": [
        "## Plot Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BxQzj34aiDz1",
        "outputId": "67752afe-c2ce-43bf-9f95-705a6ca3f186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "plt.figure(figsize=(10,15))\n",
        "\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(test_images[i].reshape(28,28), cmap = plt.cm.binary)\n",
        "    plt.axis('off')\n",
        "    color = 'green' if np.argmax(predictions[i]) == test_labels[i] else 'red'\n",
        "    plt.title('Prediction: {}\\nTrue Label: {}'.format(np.argmax(predictions[i]), test_labels[i]), color=color)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x1080 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}